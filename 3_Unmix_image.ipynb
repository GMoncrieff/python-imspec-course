{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96491b41-6987-433d-9d32-2e4b5b9fdeb2",
   "metadata": {},
   "source": [
    "# Working with multidimensional spatial data in Python\n",
    "# lesson 2.2 - Transforming imaging spectroscopy data at scale\n",
    "_Glenn Moncrieff_  \n",
    "[github.com/GMoncrieff](github.com/GMoncrieff)  \n",
    "[@glennwithtwons](https://twitter.com/glennwithtwons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093c106-f856-4e56-8fe4-7910a69ef824",
   "metadata": {},
   "source": [
    "We have now trained a model and evaluated it's predictions. Let's pretend that we are happy with it's performance (I said pretend). Now what we want to do is use the model to transfom the reflectance spectra over an entire scene into a map of the biophysical property our model predicts. That means running `model.predict()` over the entire image. Ideally, we would like to not have to do this on the entire datacube at once, as that would be mean having to load all the data into memory, and potentially limit our ability to parallelise this costly computation.  \n",
    "  \n",
    "Fortunately we can perform this task on a chunked xarray. This means we only have to load a few chunks at a time, we can stream the data chunk by chunk from s3, and we can use the dask scheduler to help parallelise the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b0265-ad94-4894-9f17-634acfbdb7af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64aaa66-87d4-45d7-bda4-389f7baeaedc",
   "metadata": {},
   "source": [
    "### Authenticate with NASA Earthdata portal\n",
    "Earthaccess is a python library to search, download or stream NASA Earth science data. You will also need an account on NASA's Earthdata data portal\n",
    "https://search.earthdata.nasa.gov/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef7711-aedf-4c4f-bbed-c88925ed6bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "auth = earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a13e47-7f96-434e-b376-1dfd720c50eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The old way\n",
    "#from utils.s3_access import write_creds\n",
    "#write_creds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915f616-ea95-467b-9e63-7a9e0d4b1c6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935d6eb-8a57-4fb5-ad61-a261f1b603ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import xarray as xr\n",
    "import rioxarray as riox\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from einops import rearrange\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#our modules\n",
    "from utils.emit_tools import emit_xarray, quality_mask, ortho_xr, gamma_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882ecba-357d-45b1-87f2-2f08d9a057da",
   "metadata": {},
   "source": [
    "## 3. Setup the dask scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c1d19-7d39-4e76-8e22-c3d9dd2648b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster, progress\n",
    "\n",
    "cluster = LocalCluster(n_workers=4)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6797f0b-4144-44b6-b5f0-9764c0e62058",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Open the datset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e77bc-dad0-4603-b8d4-5f7f9b94eee0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### If you are in us-west-2: Authenticate with s3 and stream data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19687161-2446-4c9b-958a-1341fa9a5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load s3 credentials\n",
    "from utils.s3_access import get_temp_creds\n",
    "temp_creds_req = get_temp_creds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b1c209-44c1-4607-8148-c62f2f7d04f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass Authentication to s3fs\n",
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=temp_creds_req['accessKeyId'], \n",
    "                          secret=temp_creds_req['secretAccessKey'], \n",
    "                          token=temp_creds_req['sessionToken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7205f-0ad4-4a82-b267-14fdaf394079",
   "metadata": {},
   "source": [
    "#### Link to the s3 file and have a quick look with xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23e165-af1a-4965-82aa-3a7492bce8ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#these are our files - the s3 links\n",
    "f_url = ['s3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230119T114247_2301907_005/EMIT_L2A_RFL_001_20230119T114247_2301907_005.nc',\n",
    "         's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230123T100615_2302306_006/EMIT_L2A_RFL_001_20230123T100615_2302306_006.nc']\n",
    "f_mask_url = ['s3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230119T114247_2301907_005/EMIT_L2A_MASK_001_20230119T114247_2301907_005.nc',\n",
    "            's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230123T100615_2302306_006/EMIT_L2A_MASK_001_20230123T100615_2302306_006.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75af506-0057-40de-87c6-0d5b03081d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open s3 url\n",
    "fp = fs_s3.open(f_url[0], mode='rb')\n",
    "fp_mask = fs_s3.open(f_mask_url[0], mode='rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9b3f6-dd76-43f5-94fe-53a408af01a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### If you are not in us-west-2: \n",
    "you should already have the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7272e4-7c8b-4047-8a5f-315d17e285a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "fp = 'data/downloads/EMIT_L2A_RFL_001_20230119T114247_2301907_005.nc'\n",
    "fp_mask = 'data/downloads/EMIT_L2A_MASK_001_20230119T114247_2301907_005.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1ca0e-b701-4fa7-be1a-3d91e6208c6f",
   "metadata": {},
   "source": [
    "### Load the mask\n",
    "same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166e9ea-b96f-4f31-b46f-41fe7394cb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flags=[7]\n",
    "mask = quality_mask(fp_mask,flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84975e-1cc0-4f9d-926c-1299834d7c90",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "This is different to before. Now we will use the unorthorectified data, and later orthorectify the biophysical product we produce. We will mask the data, as to do this we don't need to orthorectify because the mask is on the same grid as the image. Because we don't need to orthorectfy we can chunk and load into a `dask.array` backed `xr.Dataset`, saving us memory.\n",
    "\n",
    "> Why do we not orthorectify?   \n",
    "We may have to resample the data from the original grid of the focal plane array when we orthorectify - this can mean altering the original measured spectra. To maintain the spectroscopic fidelity of the measurements, it is better to perform all calculation and modelling using the untransformed spectra, and resample/orthorectify the downstream biophysical attributes.\n",
    "' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2b33b-ac96-4fb1-93a3-d20ac0a93905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = emit_xarray(fp, \n",
    "                 ortho=False,\n",
    "                 chunk={'downtrack':100,'crosstrack':100,'wavelengths':-1})\n",
    "#mask bad bands\n",
    "ds = ds.where(ds.good_wavelengths.compute()==1,drop=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5113951c-3b61-491f-83cd-cb3e9670a5e6",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985e938-a857-4605-8fe3-f81eb6254d2f",
   "metadata": {},
   "source": [
    "### get model\n",
    "Before we can make predictions, we need a function that will load the model from where we saved it onto the dask workers, where it can be applied to the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a3891-3188-4eab-a0a3-3879839d80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function loads the model\n",
    "\n",
    "#for the xgboost model\n",
    "def get_xgb_model():\n",
    "    model = XGBRegressor()\n",
    "    model.load_model('models/best_xgb_model.json')\n",
    "    return model\n",
    "\n",
    "#for the ROCKET model\n",
    "#def get_model():\n",
    "#    with open('models/rocketmodel.pkl', 'rb') as f:\n",
    "#        model = pickle.load(f)\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b256d8-87a5-4f8a-814a-857d9976d815",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### The short explanation\n",
    "`Client.submit()` sends tasks to the Dask scheduler. Using `fmodel = client.submit(get_xgb_model)`, the `get_xgb_model()` function runs in a worker process, returning your XGBoost model. Without `client.submit()`, worker processes won't access the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182aee0-13d4-471a-b4b4-2c6ee673054b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The long explanation\n",
    "\n",
    "The `client.submit()` function is used to send a task to the Dask distributed scheduler. When you do `fmodel = client.submit(get_xgb_model)`, you're asking the scheduler to run the `get_xgb_model()` function in one of the worker processes. This function returns your XGBoost model, and `client.submit` wraps this into a Future object (fmodel), which is a promise to a result that the scheduler will compute in the future. This means that `fmodel.result()` in pred_chunk function will fetch the XGBoost model from the worker process where it was created,  ensuring that the model can be accessed across all worker processes when applying the model to each chunk of your data. Without using `client.submit()`, your worker processes wouldn't have access to the XGBoost model, because it wouldn't be in their local memory.\n",
    "\n",
    "If you pass `get_xgb_model()` directly to `xr.apply_ufunc`, it will be evaluated once for every chunk. This means you'd be loading your model from disk each time, which is very inefficient, especially if your model is large or you have many chunks. By first doing `fmodel = client.submit(get_xgb_model)`, you ensure the model is loaded only once per worker and kept in memory. Then pred_chunk can quickly access it for each chunk. This is a typical pattern when using a model or large data structure with Dask: load it once per worker, then apply it many times. This avoids the overhead of repeatedly  loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e701e2-735e-4749-8267-e99ff447862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "fmodel = client.submit(get_xgb_model)\n",
    "#ROCKET\n",
    "#fmodel = client.submit(get_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52af673-8f13-48f4-b27e-29f423c0b26a",
   "metadata": {},
   "source": [
    "### Apply model to each chunk\n",
    "The function below will run on each chunk. The first argument `arr` is the numpy array (the chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ae11d-3ee4-443c-b693-970143dadcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function apply a transformaton to each chunk\n",
    "def pred_chunk(arr,fmodel):\n",
    "    #prep data\n",
    "    arr = arr[:,:,:-1] #dont ask, a band got dropped somewhere\n",
    "    xs, ys, zs = arr.shape #get teh shape of the chunk\n",
    "    arr = rearrange(arr,'x y z -> (x y) z') #turn stack x and y so each pixel is an obs\n",
    "    arr=np.nan_to_num(arr) #fill nas\n",
    "    \n",
    "    #predict\n",
    "    ypred = fmodel.result().predict(arr)\n",
    "    \n",
    "    #prep result\n",
    "    ypred = np.clip(ypred,0,100) #clip to 0-100\n",
    "    ypred = rearrange(ypred,'(x y) z -> x y z', x=xs,y=ys) #return to original shape\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b4626-c8d8-45cd-a2c7-ea0eda42f062",
   "metadata": {},
   "source": [
    "### Define how to apply the function to the xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c7d9-bd48-443d-b0e5-453a10f0e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = xr.apply_ufunc(pred_chunk, #the function\n",
    "                           ds, #the data\n",
    "                           input_core_dims=[['wavelengths']], #the dims we will lose in the result\n",
    "                           exclude_dims=set(('wavelengths',)), #the dims we will lose in the result\n",
    "                           output_core_dims=[[\"class\"]], #the dims we will gain in the result\n",
    "                           dask=\"parallelized\", #use dask\n",
    "                           output_dtypes=[np.uint8], #dtype of result\n",
    "                           output_sizes={\"class\": 4}, #length of new dim,\n",
    "                           keep_attrs='override',\n",
    "                           kwargs={'fmodel':fmodel}) #addiotnal args to func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9f88d-ef2e-45cc-8a5f-cfac8e69ee6b",
   "metadata": {},
   "source": [
    "Now we have the result (it has not been calculated though), next step is to mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb4b47-013a-43ae-8fe7-1d0ee179a6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qmask = mask[:,:,np.newaxis]\n",
    "res = res.where(qmask != 1,-9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2ac65-bfb1-492b-bfb9-6d7b15d91614",
   "metadata": {},
   "source": [
    "Tell dask to actually perform the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2178a8-645e-460a-b551-d70f19cc5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.persist - perform the computation in the background \n",
    "# and keep result as chunked array\n",
    "res = res.persist()\n",
    "#a progress bar if dask dashboard is not working\n",
    "progress(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb3d37-0803-4914-850d-e3ba59b515a7",
   "metadata": {},
   "source": [
    "Finally, because the result only has a few bands (one for each endmember class), rather than the 250ish in the image data cube, it can fit comfortably in memory. We need the xarray to be backed by `np.array` and not `dask.array` (i.e. not chunked) in order to be able to orthorectify.  \n",
    "  \n",
    "`.load()` turns `dask.array`s into `np.array's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15a863-3708-4dbf-91f7-f068b0afb792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = res.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9132fda-e47e-4b42-a02e-b81ccea40593",
   "metadata": {},
   "source": [
    "## 6. Orthorectify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65019c99-c683-4c05-86cd-9cd1c9cb62bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = ortho_xr(res, GLT_NODATA_VALUE=0, fill_value = -9999)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e22560-a2c8-4c08-8e2e-146909a60e65",
   "metadata": {},
   "source": [
    "### quick plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b058a-d322-4f80-a35e-c5e3f1900593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res.isel({'class':3}).hvplot.image(cmap='viridis', clim=(0,100),aspect = 'equal', frame_width=500, rasterize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4073543-4ebe-4e58-9487-c2dc5239f676",
   "metadata": {},
   "source": [
    "## 7. Save GeoTIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba26bd-7ffc-4c74-b2d2-149ab14e387a",
   "metadata": {},
   "source": [
    "We need to add some info to save as a geoTIFF using `rioxarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43065b-9f0d-4b31-8d13-71d9101f4d21",
   "metadata": {},
   "source": [
    "First lets add names for the class codes, we saved these when we encoded the strings to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda990f5-4964-4813-a976-547c7cb53abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read in class names\n",
    "classes = json.load(open(\"data/classes.json\"))\n",
    "classes = list(classes.keys())\n",
    "res.coords[\"class\"] = classes\n",
    "#convert to dataset with one var per class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad22559-8b91-45de-96f7-17c32bb5cf52",
   "metadata": {},
   "source": [
    "add the formationg that rioxarray needs for writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73159ce-3624-4af0-affd-871d3272e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = res.rio.write_crs('epsg:4326')\n",
    "res = res[\"reflectance\"].to_dataset(dim=\"class\") \n",
    "\n",
    "#our values are 0-100 so lets make then int8\n",
    "res = res.fillna(255)\n",
    "res = res.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21fe5d-e68b-4d57-a1aa-b355a1b6e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get infilename\n",
    "filename_with_ext = os.path.basename(fp.path)\n",
    "#write tif\n",
    "res.rio.to_raster(f'data/unmixed/unmixed_{os.path.splitext(filename_with_ext)[0]}.tiff',dtype='int8',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4cc847-0185-4791-bd43-462a131bee7d",
   "metadata": {},
   "source": [
    "## 8. Automate this\n",
    "\n",
    "I have provided a script that takes the code from this notebook into an executable python file that takes the input file and mask as arguments - `unmix_image.py`. This means we can iterate through a list of files and unmix them in a shell script. The script `run_unmix.sh` will go though all files listed in `data/infiles.csv` and unmix them. To run this file, run this in the terminal (only do this if you are on a machine in us-west-2):\n",
    "```\n",
    "chmod +x run_unmix.sh\n",
    "bash run_unmix.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2b9d8-8292-44ae-b9df-d49dfaa104d8",
   "metadata": {},
   "source": [
    "## credits:\n",
    "\n",
    "This lesson has borrowed from:    \n",
    "\n",
    "[the EMIT-Data-Resources repository by LPDAAC/ the EMIT team](https://github.com/nasa/EMIT-Data-Resources) \n",
    "\n",
    "[Okunjeni et al 2013 RSE for the original methodology](https://www.sciencedirect.com/science/article/abs/pii/S0034425713002009)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emitpy]",
   "language": "python",
   "name": "conda-env-emitpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
